<!-- Head start's from here (Note: This is the head section. Directly copy and paste this code)-->
<!-- Google Analytics Code -->
<script>
	/*(function(i, s, o, g, r, a, m) {
		i['GoogleAnalyticsObject'] = r;
		i[r] = i[r] ||
		function() {
			(i[r].q = i[r].q || []).push(arguments)
		}, i[r].l = 1 * new Date();
		a = s.createElement(o), m = s.getElementsByTagName(o)[0];
		a.async = 1;
		a.src = g;
		m.parentNode.insertBefore(a, m)
	})(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
	ga('create', 'UA-42369332-1', 'ijme.in');
	ga('send', 'pageview');*/ 
</script>

<!-- Javascript -->


<!-- Bootstrap -->




<!-- custom -->
<link rel="stylesheet" href="/custom/css/main.css">


<!-- Body -->
<div class="container-fluid">
	<div class="row-fluid">
		<div class="span12">
			<!-- Head end's here -->
            <!-- Section Name -->
			<h2>BOOK REVIEW</h2>
<h3>Cui bono?</h3>
<!-- Author Name and university-->
			<h4 class="author">Satyajit Rath</h4>
            <hr />
          
            	<div class="section">

<h4>Sydney A Halpern. Lesser harms: the morality of risk in medical research. 216 pages. Chicago: University of Chicago Press, 2004. ISBN 0-226-31451-0.</h4>
<p>It feels odd reviewing a book that was published three years ago (and noted in <em>IJME</em> two years ago). Why is it worthwhile reviewing so long after publication a dryly written sociological monograph built around a case study of risk determination processes in early 20th-century clinical trials of polio vaccines? The answer lies in the accelerating industrialisation of clinical research, the elephant in the room that Halpern's book continually skirts around, never quite addressing it directly, yet evidently aware of its presence as demonstrated by her last, almost ideological chapter. But let me start at the beginning.</p>
<p>What is the book about? Starting from a brief historical survey of earlier vaccine trials, it examines the moral processes involved in the polio vaccine trials, in the USA, first in the 1930s and then in the 1950s. It argues plausibly that the trials of the 1930s had informal, non-institutionalised moral frameworks driven by the logic of lesser harm. The morality of "lesser harm" means, for Halpern, the argument that no clinical intervention that is riskier than the disease itself should be attempted even experimentally. Her analysis underlines the inherent limitations of informal moralities; that they cannot be "enforced" on people who are already peripheral in the peer community. She then goes on to show the paradox of the 1950s: the evolution of far more institutionalised structures governing moral decision making about clinical experiments, contemporaneous with the execution (innuendo intended) of clinical experiments in flagrant violation of the moral position of "lesser harm". She argues that this became possible because institutionalisation robbed the process of moral urgency by reducing it to ritual motions to be gone through, because problem groups of scientists intimately knowledgeable about the specific issues involved were replaced as arbiters by committees far more superficial in their expertise, and (slightly less persuasively for me) because the moral climate of the society in the USA was more conducive in the 1950s than in the 1930s to individual sacrifice for the public (or "national", which is not quite the same thing) good.</p>
<p>Halpern's analysis is far more nuanced (and interesting) than is suggested by this bald summary, but to discuss the many issues in social history the book throws up would require far more space than available here. The volume also offers some curiously insightful asides: the fact (new to me) that cowpox and smallpox were thought of as the same infection (passaged in cows or not, according to the <em>London Times</em>) in the 19th century variolation/vaccination debates, or the ironic double meaning created by Halpern's American usage when she characterises the research community as the bearer of moral "oversight", are particularly striking examples. However, comments on some curious omissions may not be out of place before coming back to the elephant. First, perhaps because she uses "narrative" analysis in the traditions of social science, Halpern misses discussing a major issue: the quantitative nature of "risk" and, as a sub-theme in that context, the connections between the evolving trends in biostatistical theory and the risk perceptions of the scientific community over the period she is discussing.</p>
<p>Second, Halpern refers to the anti-vivisectionist movement (or at least anti-vivisectionist public opinion) as a major factor shaping both the moralities and the choices of researchers, but she does not explore the roots and positions of that movement. She talks of so-called "hard" and "moderate" anti-vivisectionist positions. The first argues for proscription of all animal and human experimentation; and the latter argues for "extensive" animal testing before human trials following a notion of "lesser harm". How then did the researchers Halpern analyses and their critics view the obvious moral contradictions involved? This is a particularly striking lacuna since there was then (and continues to be now) a significant stream of anti-vivisectionist opinion within medical practitioners, a community that forms part of Halpern's analytical focus.</p>
<p>Third, Halpern uses the idea of lesser harm as a moral imperative to prohibit experimentation, and cites individual researchers approvingly as being the bearers of personal consciences (passing an implicit, unexplored judgement of the absence of personal consciences in other researchers), but she does not explore the possibility that the absence or proscription of experimentation may in itself constitute a form of experimentation subject to morality, as also the idea of the social responsibility of individuals in terms of the imposition of transmission risk on others.</p>
<p>Fourth, Halpern's claim that the moral logic of the researchers she is investigating was largely technical rather than social in origin seems a bit too linear an interpretation. Curiously, Halpern says that self-experimentation lay outside the techniques of modern science in attempting to claim credibility based on personal honour and integrity, and was thus a non-technical component in the moral fabric of researcher behaviour. But can it not be seen as an attempt to provide an empirical basis for personal integrity, and thus be treated as a technical source of moral logic?</p>
<p>On the other hand, Halpern makes no effort to answer the elephant-in-the-room question: cui bono? Who benefits? Why did researchers research? Why did they bother to contest the anti-vivisectionist narrative? The answers to such questions, which are directly related to the construction of the moral logic of researchers, are likely to be both "moral" in the sense of public interest and "social" in the sense of both monetary and power returns, issues connected to the professionalisation of medicine.</p>
<p>Halpern repeatedly refers to the professionalisation of medicine and its impact on the shaping of researcher moralities, as well as on their public perceptions. But she does not explore how the morality of the doctor-patient relationship was constructed in the pre-professional versus the professional versions of medical practice. Nonetheless, she at least implies that the idea of "lesser harm" belongs to the pre-professional framework in which the physician was morally responsible, and that the notion of informed consent contributed to the transfer of moral responsibility onto the patient as the recipient of "professional" advice. Clearly, professionalisation of medicine and the corporatisation of the health industry went hand in hand, possibly synergistically, and both were plausibly linked to the expanded access to profits and power involved. In other words, money and power (and class), organised capital, contributed to the abrogation of moral responsibility. This is an issue that, as I said, Halpern continually hints at, but does not ever address directly, much to my disappointment.</p>
<p>My disappointment is particularly acute since, over the past few years since Halpern's book was published, the health care scenario in India has shown a steady growth both of the corporate model of health care and of contracted, industry-driven clinical research. In such a scenario the performance of riskier experiments/trials may, in a plausible paradox, go hand in hand with increased formal institutional regulatory supervision based on the principle of informed consent, since problem groups of researchers are not involved in regulation and since large corporate returns are at stake. In these times Halpern's book is a spur to thinking about the ways and means of diversifying the basis of ethical regulation from informed consent alone to the inclusion of principles of lesser harm and of researcher moralities.</p>
</div>
</div>
</div>
</div>

